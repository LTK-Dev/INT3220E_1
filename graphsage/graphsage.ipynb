{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd1d1f64",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-30T08:09:53.752602Z",
     "iopub.status.busy": "2025-11-30T08:09:53.752356Z",
     "iopub.status.idle": "2025-11-30T08:09:55.005186Z",
     "shell.execute_reply": "2025-11-30T08:09:55.004371Z"
    },
    "papermill": {
     "duration": 1.259544,
     "end_time": "2025-11-30T08:09:55.006475",
     "exception": false,
     "start_time": "2025-11-30T08:09:53.746931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/lmtracker/__results__.html\n",
      "/kaggle/input/lmtracker/__notebook__.ipynb\n",
      "/kaggle/input/lmtracker/__output__.json\n",
      "/kaggle/input/lmtracker/custom.css\n",
      "/kaggle/input/lmtracker/graph_data_20251119174904/malicious_test_path.pt\n",
      "/kaggle/input/lmtracker/graph_data_20251119174904/graph_data_torch.pt\n",
      "/kaggle/input/lmtracker/graph_data_20251119174904/malicious_train_val_path.pt\n",
      "/kaggle/input/lmtracker/graph_data_20251119174904/computer2nodeid.pt\n",
      "/kaggle/input/lmtracker/graph_data_20251119174904/process2nodeid.pt\n",
      "/kaggle/input/lmtracker/graph_data_20251119174904/user2nodeid.pt\n",
      "/kaggle/input/lmtracker/graph_data_20251119174904/normal_path.pt\n",
      "/kaggle/input/lmtracker/graph_data_20251119174904/graph_data_dgl.bin\n",
      "/kaggle/input/lmtracker/graph_data_20251119174904/malicious_CUC_path.pt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35f3e677",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T08:09:55.015961Z",
     "iopub.status.busy": "2025-11-30T08:09:55.015458Z",
     "iopub.status.idle": "2025-11-30T08:13:23.215721Z",
     "shell.execute_reply": "2025-11-30T08:13:23.214927Z"
    },
    "papermill": {
     "duration": 208.206991,
     "end_time": "2025-11-30T08:13:23.217362",
     "exception": false,
     "start_time": "2025-11-30T08:09:55.010371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping torch-scatter as it is not installed.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torch-cluster as it is not installed.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torch-spline-conv as it is not installed.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torch-geometric as it is not installed.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Skipping pyg-lib as it is not installed.\u001b[0m\u001b[33m\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m799.1/799.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m105.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m989.8/989.8 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 GB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m163.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "nx-cugraph-cu12 25.6.0 requires pylibcugraph-cu12==25.6.*, but you have pylibcugraph-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# 1. Gá»¡ háº¿t cÃ¡c thá»© cÅ© cÃ³ thá»ƒ gÃ¢y xung Ä‘á»™t\n",
    "!pip uninstall -y torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric pyg-lib -q\n",
    "\n",
    "# 2. CÃ i Ä‘Ãºng phiÃªn báº£n torch + cu121 hiá»‡n táº¡i cá»§a Colab (ráº¥t quan trá»ng)\n",
    "!pip install torch==2.4.0+cu121 torchvision==0.19.0+cu121 torchaudio==2.4.0+cu121 --extra-index-url https://download.pytorch.org/whl/cu121 -q\n",
    "\n",
    "# 3. CÃ i PyG + cÃ¡c package phá»¥ thuá»™c tá»« wheel chÃ­nh thá»©c (dÃ¹ng torch 2.4.0 má»›i nháº¥t)\n",
    "!pip install torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.4.0+cu121.html -q\n",
    "!pip install torch_geometric -q\n",
    "\n",
    "# 4. CÃ i cÃ¡c package phá»¥ thÆ°á»ng cáº§n thÃªm\n",
    "!pip install pyg_lib torch_spline_conv -f https://data.pyg.org/whl/torch-2.4.0+cu121.html -q\n",
    "\n",
    "# 5. (Tuá»³ chá»n) Náº¿u váº«n cÃ²n lá»—i cuGraph â†’ downgrade táº¡m Ä‘á»ƒ khá»i conflict\n",
    "!pip install libcugraph-cu12==25.2.* pylibcugraph-cu12==25.2.* libraft-cu12==25.2.* rmm-cu12==25.2.* --extra-index-url=https://pypi.nvidia.com -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "467ad05e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T08:13:23.295164Z",
     "iopub.status.busy": "2025-11-30T08:13:23.294858Z",
     "iopub.status.idle": "2025-11-30T08:13:32.123629Z",
     "shell.execute_reply": "2025-11-30T08:13:32.122788Z"
    },
    "papermill": {
     "duration": 8.870375,
     "end_time": "2025-11-30T08:13:32.125081",
     "exception": false,
     "start_time": "2025-11-30T08:13:23.254706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… torch_scatter OK\n",
      "âœ… torch_sparse OK\n",
      "âœ… torch_cluster OK\n",
      "âœ… torch_spline_conv OK\n",
      "PyG: 2.7.0\n"
     ]
    }
   ],
   "source": [
    "import torch_scatter, torch_sparse, torch_cluster, torch_spline_conv\n",
    "import torch_geometric\n",
    "from torch_sparse import SparseTensor\n",
    "\n",
    "print(\"âœ… torch_scatter OK\")\n",
    "print(\"âœ… torch_sparse OK\")\n",
    "print(\"âœ… torch_cluster OK\")\n",
    "print(\"âœ… torch_spline_conv OK\")\n",
    "print(\"PyG:\", torch_geometric.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11fe8faf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T08:13:32.201878Z",
     "iopub.status.busy": "2025-11-30T08:13:32.201276Z",
     "iopub.status.idle": "2025-11-30T08:13:32.208429Z",
     "shell.execute_reply": "2025-11-30T08:13:32.207661Z"
    },
    "papermill": {
     "duration": 0.046431,
     "end_time": "2025-11-30T08:13:32.209573",
     "exception": false,
     "start_time": "2025-11-30T08:13:32.163142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Gá»i hÃ m nÃ y trÆ°á»›c khi cháº¡y báº¥t cá»© thá»© gÃ¬ khÃ¡c\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcdbbce7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T08:13:32.289224Z",
     "iopub.status.busy": "2025-11-30T08:13:32.288548Z",
     "iopub.status.idle": "2025-11-30T08:13:32.306884Z",
     "shell.execute_reply": "2025-11-30T08:13:32.305897Z"
    },
    "papermill": {
     "duration": 0.058866,
     "end_time": "2025-11-30T08:13:32.307995",
     "exception": false,
     "start_time": "2025-11-30T08:13:32.249129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Searching for lmTracker output folder...\n",
      "âœ… Found lmTracker directory:\n",
      "/kaggle/input/lmtracker/graph_data_20251119174904\n",
      "\n",
      "ğŸ“‚ Files inside this directory:\n",
      "   â”œâ”€ computer2nodeid.pt\n",
      "   â”œâ”€ graph_data_dgl.bin\n",
      "   â”œâ”€ graph_data_torch.pt\n",
      "   â”œâ”€ malicious_CUC_path.pt\n",
      "   â”œâ”€ malicious_test_path.pt\n",
      "   â”œâ”€ malicious_train_val_path.pt\n",
      "   â”œâ”€ normal_path.pt\n",
      "   â”œâ”€ process2nodeid.pt\n",
      "   â”œâ”€ user2nodeid.pt\n",
      "\n",
      "\n",
      "ğŸ“Œ Checking required files...\n",
      "\n",
      "âœ… Found: graph_data_torch.pt\n",
      "âœ… Found: normal_path.pt\n",
      "âœ… Found: malicious_CUC_path.pt\n",
      "âœ… Found: malicious_train_val_path.pt\n",
      "âœ… Found: malicious_test_path.pt\n",
      "âœ… Found: computer2nodeid.pt\n",
      "âœ… Found: user2nodeid.pt\n",
      "\n",
      "ğŸ‰ All required files exist! Dataset is READY.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "REQUIRED_FILES = [\n",
    "    \"graph_data_torch.pt\",\n",
    "    \"normal_path.pt\",\n",
    "    \"malicious_CUC_path.pt\",\n",
    "    \"malicious_train_val_path.pt\",\n",
    "    \"malicious_test_path.pt\",\n",
    "    \"computer2nodeid.pt\",\n",
    "    \"user2nodeid.pt\",\n",
    "]\n",
    "\n",
    "def find_lmtracker_dir(base_dir=\"/kaggle/input/lmtracker\"):\n",
    "    \"\"\"\n",
    "    TÃ¬m thÆ° má»¥c chá»©a graph_data_torch.pt vÃ  toÃ n bá»™ file output lmTracker.\n",
    "    CÃ³ thá»ƒ náº±m trá»±c tiáº¿p bÃªn trong hoáº·c trong thÆ° má»¥c con.\n",
    "    \"\"\"\n",
    "    # TH1: file náº±m trá»±c tiáº¿p\n",
    "    if \"graph_data_torch.pt\" in os.listdir(base_dir):\n",
    "        return base_dir\n",
    "\n",
    "    # TH2: file náº±m trong thÆ° má»¥c con\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        if \"graph_data_torch.pt\" in files:\n",
    "            return root\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "print(\"ğŸ” Searching for lmTracker output folder...\")\n",
    "\n",
    "lm_dir = find_lmtracker_dir()\n",
    "\n",
    "if lm_dir is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"âŒ KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c chá»©a graph_data_torch.pt trong /kaggle/input/lmtracker.\\n\"\n",
    "        \"â¡ HÃ£y kiá»ƒm tra láº¡i báº¡n Ä‘Ã£ attach Ä‘Ãºng dataset lmTracker hay chÆ°a.\"\n",
    "    )\n",
    "\n",
    "print(f\"âœ… Found lmTracker directory:\\n{lm_dir}\\n\")\n",
    "\n",
    "# In toÃ n bá»™ file cÃ³ trong thÆ° má»¥c Ä‘Ã³\n",
    "print(\"ğŸ“‚ Files inside this directory:\")\n",
    "for f in sorted(os.listdir(lm_dir)):\n",
    "    print(\"   â”œâ”€\", f)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Check thiáº¿u file nÃ o khÃ´ng\n",
    "print(\"ğŸ“Œ Checking required files...\\n\")\n",
    "missing_files = []\n",
    "\n",
    "for fname in REQUIRED_FILES:\n",
    "    fpath = os.path.join(lm_dir, fname)\n",
    "    if not os.path.isfile(fpath):\n",
    "        missing_files.append(fname)\n",
    "        print(f\"âŒ Missing: {fname}\")\n",
    "    else:\n",
    "        print(f\"âœ… Found: {fname}\")\n",
    "\n",
    "if missing_files:\n",
    "    print(\"\\nâš ï¸ WARNING: Dataset thiáº¿u file sau:\")\n",
    "    for f in missing_files:\n",
    "        print(\"   -\", f)\n",
    "    print(\"\\nâ— Code MetaPath2Vec sáº½ lá»—i náº¿u thiáº¿u cÃ¡c file nÃ y.\")\n",
    "else:\n",
    "    print(\"\\nğŸ‰ All required files exist! Dataset is READY.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882297e0",
   "metadata": {
    "papermill": {
     "duration": 0.037131,
     "end_time": "2025-11-30T08:13:32.382932",
     "exception": false,
     "start_time": "2025-11-30T08:13:32.345801",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GraphSAGE Model Implementation for Heterogeneous Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1b6a5bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T08:13:32.457946Z",
     "iopub.status.busy": "2025-11-30T08:13:32.457428Z",
     "iopub.status.idle": "2025-11-30T08:13:32.468568Z",
     "shell.execute_reply": "2025-11-30T08:13:32.467845Z"
    },
    "papermill": {
     "duration": 0.050077,
     "end_time": "2025-11-30T08:13:32.469604",
     "exception": false,
     "start_time": "2025-11-30T08:13:32.419527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from typing import Dict\n",
    "from torch_geometric.nn import SAGEConv, HeteroConv\n",
    "\n",
    "class HeteroGraphSAGE(nn.Module):\n",
    "    \"\"\"\n",
    "    GraphSAGE cho Ä‘á»“ thá»‹ dá»‹ thá»ƒ (Computer, User, Process, ...).\n",
    "\n",
    "    - Má»—i node type cÃ³ 1 embedding riÃªng.\n",
    "    - Má»—i edge type dÃ¹ng 1 SAGEConv (GraphSAGE).\n",
    "    - DÃ¹ng HeteroConv Ä‘á»ƒ gá»™p message tá»« nhiá»u edge type.\n",
    "    - Tráº£ vá» x_dict: embedding out_channels cho tá»«ng node type.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        metadata,\n",
    "        num_nodes_dict: Dict[str, int],\n",
    "        hidden_channels: int = 128,\n",
    "        out_channels: int = 128,\n",
    "        num_layers: int = 2,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.metadata = metadata\n",
    "        self.node_types, self.edge_types = metadata\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # 1) Trainable embedding cho tá»«ng loáº¡i node\n",
    "        self.embeddings = nn.ModuleDict()\n",
    "        for nt in self.node_types:\n",
    "            n = num_nodes_dict[nt]\n",
    "            self.embeddings[nt] = nn.Embedding(n, hidden_channels)\n",
    "\n",
    "        # 2) HeteroConv gá»“m nhiá»u SAGEConv cho tá»«ng edge type\n",
    "        self.convs = nn.ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            conv = HeteroConv(\n",
    "                {\n",
    "                    # KHÃ”NG dÃ¹ng (-1, -1) Ä‘á»ƒ trÃ¡nh LazyModule\n",
    "                    edge_type: SAGEConv((hidden_channels, hidden_channels), hidden_channels)\n",
    "                    for edge_type in self.edge_types\n",
    "                },\n",
    "                aggr=\"sum\",  # sum/mean/max: aggregate giá»¯a cÃ¡c edge type\n",
    "            )\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        # 3) Linear chiáº¿u ra out_channels cho tá»«ng node type\n",
    "        self.lin_out = nn.ModuleDict()\n",
    "        for nt in self.node_types:\n",
    "            self.lin_out[nt] = nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for nt in self.node_types:\n",
    "            nn.init.xavier_uniform_(self.embeddings[nt].weight)\n",
    "        for conv in self.convs:\n",
    "            for m in conv.modules():\n",
    "                if isinstance(m, SAGEConv):\n",
    "                    m.reset_parameters()\n",
    "        for nt in self.node_types:\n",
    "            nn.init.xavier_uniform_(self.lin_out[nt].weight)\n",
    "            if self.lin_out[nt].bias is not None:\n",
    "                nn.init.zeros_(self.lin_out[nt].bias)\n",
    "\n",
    "    def forward(self, edge_index_dict):\n",
    "        \"\"\"\n",
    "        edge_index_dict: data.edge_index_dict (Ä‘Ã£ .to(device))\n",
    "        Tráº£ vá»: dict[node_type] -> tensor [num_nodes_type, out_channels]\n",
    "        \"\"\"\n",
    "        # 1) Init embedding cho tá»«ng node type: x_dict[nt] âˆˆ [N_nt, hidden]\n",
    "        x_dict = {}\n",
    "        for nt in self.node_types:\n",
    "            num_nodes = self.embeddings[nt].num_embeddings\n",
    "            idx = torch.arange(num_nodes, device=self.embeddings[nt].weight.device)\n",
    "            x_dict[nt] = self.embeddings[nt](idx)\n",
    "\n",
    "        # 2) Message passing qua tá»«ng layer\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x_dict = conv(x_dict, edge_index_dict)  # dict[nt] âˆˆ [N_nt, hidden]\n",
    "            if i < len(self.convs) - 1:\n",
    "                for nt in x_dict:\n",
    "                    x_dict[nt] = F.relu(x_dict[nt])\n",
    "                    x_dict[nt] = F.dropout(x_dict[nt], p=self.dropout, training=self.training)\n",
    "\n",
    "        # 3) Linear + L2 normalize\n",
    "        out_dict = {}\n",
    "        for nt in x_dict:\n",
    "            h = self.lin_out[nt](x_dict[nt])          # [N_nt, out_channels]\n",
    "            h = F.normalize(h, p=2, dim=-1)           # chuáº©n hoÃ¡ L2\n",
    "            out_dict[nt] = h\n",
    "        return out_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827d74e8",
   "metadata": {
    "papermill": {
     "duration": 0.036646,
     "end_time": "2025-11-30T08:13:32.544175",
     "exception": false,
     "start_time": "2025-11-30T08:13:32.507529",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GraphSAGE Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91315eca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T08:13:32.618681Z",
     "iopub.status.busy": "2025-11-30T08:13:32.618251Z",
     "iopub.status.idle": "2025-11-30T08:13:32.621562Z",
     "shell.execute_reply": "2025-11-30T08:13:32.621064Z"
    },
    "papermill": {
     "duration": 0.041257,
     "end_time": "2025-11-30T08:13:32.622539",
     "exception": false,
     "start_time": "2025-11-30T08:13:32.581282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, datetime, time, math, random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d0072c",
   "metadata": {
    "papermill": {
     "duration": 0.036099,
     "end_time": "2025-11-30T08:13:32.694807",
     "exception": false,
     "start_time": "2025-11-30T08:13:32.658708",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Load graph lmtracker & file path CUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13799cef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T08:13:32.768332Z",
     "iopub.status.busy": "2025-11-30T08:13:32.768096Z",
     "iopub.status.idle": "2025-11-30T08:13:33.358285Z",
     "shell.execute_reply": "2025-11-30T08:13:33.357505Z"
    },
    "papermill": {
     "duration": 0.628864,
     "end_time": "2025-11-30T08:13:33.359523",
     "exception": false,
     "start_time": "2025-11-30T08:13:32.730659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Using graph directory: /kaggle/input/lmtracker/graph_data_20251119174904\n",
      "HeteroData(\n",
      "  (Computer, Connect, Computer)={ edge_index=[2, 215858] },\n",
      "  (User, Logon, Computer)={ edge_index=[2, 266232] },\n",
      "  (Computer, Logon_rev, User)={ edge_index=[2, 266232] },\n",
      "  (User, SwitchUser, User)={ edge_index=[2, 5634] },\n",
      "  (Computer, Create, Process)={ edge_index=[2, 1334355] },\n",
      "  (Process, Create_rev, Computer)={ edge_index=[2, 1334355] }\n",
      ")\n",
      "ğŸ–¥ï¸ Device: cuda\n"
     ]
    }
   ],
   "source": [
    "def find_graph_dir(base_dir: str = \"/kaggle/input/lmtracker\") -> str:\n",
    "    direct = os.path.join(base_dir, \"graph_data_torch.pt\")\n",
    "    if os.path.isfile(direct):\n",
    "        return base_dir\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        if \"graph_data_torch.pt\" in files:\n",
    "            return root\n",
    "    raise FileNotFoundError(\"KhÃ´ng tÃ¬m tháº¥y graph_data_torch.pt trong /kaggle/input/lmtracker\")\n",
    "\n",
    "dir_save = find_graph_dir()\n",
    "print(\"ğŸ“‚ Using graph directory:\", dir_save)\n",
    "\n",
    "# HeteroData\n",
    "data = torch.load(os.path.join(dir_save, \"graph_data_torch.pt\"), weights_only=False)\n",
    "print(data)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"ğŸ–¥ï¸ Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f845a3",
   "metadata": {
    "papermill": {
     "duration": 0.109636,
     "end_time": "2025-11-30T08:13:33.506629",
     "exception": false,
     "start_time": "2025-11-30T08:13:33.396993",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Metadata & num_nodes cho tá»«ng node type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab447620",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T08:13:33.581395Z",
     "iopub.status.busy": "2025-11-30T08:13:33.581108Z",
     "iopub.status.idle": "2025-11-30T08:13:33.772330Z",
     "shell.execute_reply": "2025-11-30T08:13:33.771417Z"
    },
    "papermill": {
     "duration": 0.230222,
     "end_time": "2025-11-30T08:13:33.773508",
     "exception": false,
     "start_time": "2025-11-30T08:13:33.543286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_nodes_dict: {'Computer': 15432, 'User': 11337, 'Process': 31026}\n",
      "metadata_raw: ([], [('Computer', 'Connect', 'Computer'), ('User', 'Logon', 'Computer'), ('Computer', 'Logon_rev', 'User'), ('User', 'SwitchUser', 'User'), ('Computer', 'Create', 'Process'), ('Process', 'Create_rev', 'Computer')])\n",
      "âœ… Fixed metadata: (['Computer', 'User', 'Process'], [('Computer', 'Connect', 'Computer'), ('User', 'Logon', 'Computer'), ('Computer', 'Logon_rev', 'User'), ('User', 'SwitchUser', 'User'), ('Computer', 'Create', 'Process'), ('Process', 'Create_rev', 'Computer')])\n",
      "\n",
      "ğŸ“Š num_nodes_computer = 15,432\n"
     ]
    }
   ],
   "source": [
    "def infer_num_nodes_per_type(data):\n",
    "    num_nodes = defaultdict(int)\n",
    "    for (src, rel, dst), edge_index in data.edge_index_dict.items():\n",
    "        row, col = edge_index\n",
    "        if row.numel() > 0:\n",
    "            num_nodes[src] = max(num_nodes[src], int(row.max().item()) + 1)\n",
    "        if col.numel() > 0:\n",
    "            num_nodes[dst] = max(num_nodes[dst], int(col.max().item()) + 1)\n",
    "    return dict(num_nodes)\n",
    "\n",
    "num_nodes_dict = infer_num_nodes_per_type(data)\n",
    "print(\"num_nodes_dict:\", num_nodes_dict)\n",
    "\n",
    "metadata_raw = data.metadata()\n",
    "print(\"metadata_raw:\", metadata_raw)\n",
    "\n",
    "# Náº¿u node_types rá»—ng, tá»± láº¥y tá»« num_nodes_dict\n",
    "node_types = list(num_nodes_dict.keys())\n",
    "edge_types = metadata_raw[1]\n",
    "metadata = (node_types, edge_types)\n",
    "print(\"âœ… Fixed metadata:\", metadata)\n",
    "\n",
    "\n",
    "# Sá»‘ node Computer (Ä‘á»ƒ sampling + build Câ€“C graph)\n",
    "num_nodes_computer = num_nodes_dict[\"Computer\"]\n",
    "print(f\"\\nğŸ“Š num_nodes_computer = {num_nodes_computer:,}\")\n",
    "\n",
    "# edge_index_dict trÃªn GPU (cho model)\n",
    "edge_index_dict_device = {\n",
    "    k: v.to(device) for k, v in data.edge_index_dict.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bde02e",
   "metadata": {
    "papermill": {
     "duration": 0.037394,
     "end_time": "2025-11-30T08:13:33.849802",
     "exception": false,
     "start_time": "2025-11-30T08:13:33.812408",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Sinh Câ€“Uâ€“C path random (giá»‘ng metapath CUC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2deb68a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T08:13:33.924086Z",
     "iopub.status.busy": "2025-11-30T08:13:33.923783Z",
     "iopub.status.idle": "2025-11-30T08:13:35.930659Z",
     "shell.execute_reply": "2025-11-30T08:13:35.929810Z"
    },
    "papermill": {
     "duration": 2.045726,
     "end_time": "2025-11-30T08:13:35.931837",
     "exception": false,
     "start_time": "2025-11-30T08:13:33.886111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ Sampling Câ€“Uâ€“C metapaths (CPU)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15432/15432 [00:00<00:00, 360890.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Generated 15421 unique C-U-C paths (random)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metapath = [\n",
    "    ('Computer', 'Logon_rev', 'User'),\n",
    "    ('User', 'Logon', 'Computer'),\n",
    "]  # C -> U -> C\n",
    "\n",
    "def generate_metapath_sampling(sample=20_000):\n",
    "    \"\"\"\n",
    "    Táº¡o cÃ¡c path dáº¡ng C-U-C báº±ng random walk theo metapath trÃªn CPU.\n",
    "    Index trong path lÃ  local index theo tá»«ng node type (nhÆ° file lmtracker).\n",
    "    \"\"\"\n",
    "    # adj: (src,rel,dst) -> {src_id: [dst_ids]}\n",
    "    adj = {}\n",
    "    for (src, rel, dst), edge_index in data.edge_index_dict.items():\n",
    "        row, col = edge_index\n",
    "        for u, v in zip(row.tolist(), col.tolist()):\n",
    "            adj.setdefault((src, rel, dst), {}).setdefault(int(u), []).append(int(v))\n",
    "\n",
    "    start_type = metapath[0][0]  # 'Computer'\n",
    "    start_nodes = list(range(num_nodes_computer))\n",
    "    random.shuffle(start_nodes)\n",
    "\n",
    "    paths = []\n",
    "    print(\"\\nğŸ”„ Sampling Câ€“Uâ€“C metapaths (CPU)...\")\n",
    "    for s in tqdm(start_nodes):\n",
    "        if len(paths) >= sample:\n",
    "            break\n",
    "        cur = s\n",
    "        seq = [int(cur)]\n",
    "        ok = True\n",
    "        for edge_key in metapath:\n",
    "            neighbors = adj.get(edge_key, {}).get(int(cur), [])\n",
    "            if not neighbors:\n",
    "                ok = False\n",
    "                break\n",
    "            cur = random.choice(neighbors)\n",
    "            seq.append(int(cur))\n",
    "        if ok and len(seq) == 3:\n",
    "            # seq = [C0, U1, C2]\n",
    "            paths.append((seq[0], seq[1], seq[2]))\n",
    "\n",
    "    paths = list(set(paths))\n",
    "    print(f\"âœ… Generated {len(paths)} unique C-U-C paths (random)\")\n",
    "    return paths\n",
    "\n",
    "random_paths = generate_metapath_sampling(sample=20_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b44952b",
   "metadata": {
    "papermill": {
     "duration": 0.037223,
     "end_time": "2025-11-30T08:13:36.007176",
     "exception": false,
     "start_time": "2025-11-30T08:13:35.969953",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Load cÃ¡c path CUC normal/malicious tá»« lmtracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28f21b1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T08:13:36.082201Z",
     "iopub.status.busy": "2025-11-30T08:13:36.081430Z",
     "iopub.status.idle": "2025-11-30T08:13:36.413421Z",
     "shell.execute_reply": "2025-11-30T08:13:36.412655Z"
    },
    "papermill": {
     "duration": 0.370848,
     "end_time": "2025-11-30T08:13:36.414710",
     "exception": false,
     "start_time": "2025-11-30T08:13:36.043862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“¥ Loading labeled Câ€“Uâ€“C paths (CUC) from lmtracker...\n",
      "   normal_path: 483426\n",
      "   malicious_all_path: 317\n",
      "   malicious_train_val_path: 198\n",
      "   malicious_test_path: 168\n",
      "\n",
      "ğŸ“Š Total paths for classification: 15738\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nğŸ“¥ Loading labeled Câ€“Uâ€“C paths (CUC) from lmtracker...\")\n",
    "\n",
    "normal_path = list(torch.load(os.path.join(dir_save, \"normal_path.pt\"), weights_only=False))\n",
    "malicious_all_path = list(torch.load(os.path.join(dir_save, \"malicious_CUC_path.pt\"), weights_only=False))\n",
    "malicious_train_val_path = list(torch.load(os.path.join(dir_save, \"malicious_train_val_path.pt\"), weights_only=False))\n",
    "malicious_test_path = list(torch.load(os.path.join(dir_save, \"malicious_test_path.pt\"), weights_only=False))\n",
    "\n",
    "print(f\"   normal_path: {len(normal_path)}\")\n",
    "print(f\"   malicious_all_path: {len(malicious_all_path)}\")\n",
    "print(f\"   malicious_train_val_path: {len(malicious_train_val_path)}\")\n",
    "print(f\"   malicious_test_path: {len(malicious_test_path)}\")\n",
    "\n",
    "# Dataset dÃ¹ng cho logistic regression: random_paths (normal) + malicious_all_path\n",
    "all_paths_for_cls = random_paths + malicious_all_path\n",
    "labels = [0] * len(random_paths) + [1] * len(malicious_all_path)\n",
    "print(f\"\\nğŸ“Š Total paths for classification: {len(all_paths_for_cls)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a28573",
   "metadata": {
    "papermill": {
     "duration": 0.037027,
     "end_time": "2025-11-30T08:13:36.489326",
     "exception": false,
     "start_time": "2025-11-30T08:13:36.452299",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. XÃ¢y homogeneous graph Câ€“C: edge (C0, C2) náº¿u tá»“n táº¡i Câ€“Uâ€“C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1978bc68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T08:13:36.564355Z",
     "iopub.status.busy": "2025-11-30T08:13:36.563873Z",
     "iopub.status.idle": "2025-11-30T08:13:36.798534Z",
     "shell.execute_reply": "2025-11-30T08:13:36.797532Z"
    },
    "papermill": {
     "duration": 0.273944,
     "end_time": "2025-11-30T08:13:36.799986",
     "exception": false,
     "start_time": "2025-11-30T08:13:36.526042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§± Câ€“C graph edges: 998,328\n"
     ]
    }
   ],
   "source": [
    "def build_computer_graph_from_paths(path_list_list):\n",
    "    \"\"\"\n",
    "    path_list_list: list cÃ¡c list-path, má»—i path lÃ  (C, U, C)\n",
    "    Tráº£ vá» edge_index Câ€“C (undirected) trÃªn device.\n",
    "    \"\"\"\n",
    "    edges_src = []\n",
    "    edges_dst = []\n",
    "\n",
    "    for paths in path_list_list:\n",
    "        for (c0, u, c2) in paths:\n",
    "            if c0 < 0 or c0 >= num_nodes_computer:\n",
    "                continue\n",
    "            if c2 < 0 or c2 >= num_nodes_computer:\n",
    "                continue\n",
    "            edges_src.append(c0)\n",
    "            edges_dst.append(c2)\n",
    "            # undirected\n",
    "            edges_src.append(c2)\n",
    "            edges_dst.append(c0)\n",
    "\n",
    "    edge_index = torch.tensor([edges_src, edges_dst], dtype=torch.long, device=device)\n",
    "    return edge_index\n",
    "\n",
    "edge_index_cc = build_computer_graph_from_paths(\n",
    "    [normal_path, random_paths, malicious_all_path]\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"\\nğŸ§± Câ€“C graph edges: {edge_index_cc.size(1):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfb469a",
   "metadata": {
    "papermill": {
     "duration": 0.036898,
     "end_time": "2025-11-30T08:13:36.875142",
     "exception": false,
     "start_time": "2025-11-30T08:13:36.838244",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. Khá»Ÿi táº¡o & train HeteroGraphSAGE trÃªn Ä‘á»“ thá»‹ dá»‹ thá»ƒ, loss trÃªn Câ€“C graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c346f21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T08:13:36.949581Z",
     "iopub.status.busy": "2025-11-30T08:13:36.948997Z",
     "iopub.status.idle": "2025-11-30T08:13:37.104566Z",
     "shell.execute_reply": "2025-11-30T08:13:37.103816Z"
    },
    "papermill": {
     "duration": 0.194101,
     "end_time": "2025-11-30T08:13:37.105777",
     "exception": false,
     "start_time": "2025-11-30T08:13:36.911676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… HeteroGraphSAGE params: 7,842,048\n"
     ]
    }
   ],
   "source": [
    "model = HeteroGraphSAGE(\n",
    "    metadata=metadata,\n",
    "    num_nodes_dict=num_nodes_dict,\n",
    "    hidden_channels=128,\n",
    "    out_channels=128,\n",
    "    num_layers=2,\n",
    "    dropout=0.1,\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003, weight_decay=1e-4)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"âœ… HeteroGraphSAGE params: {total_params:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f3a3c43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T08:13:37.183492Z",
     "iopub.status.busy": "2025-11-30T08:13:37.182926Z",
     "iopub.status.idle": "2025-11-30T08:14:00.657797Z",
     "shell.execute_reply": "2025-11-30T08:14:00.656836Z"
    },
    "papermill": {
     "duration": 23.515023,
     "end_time": "2025-11-30T08:14:00.658944",
     "exception": false,
     "start_time": "2025-11-30T08:13:37.143921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¥ Start training HeteroGraphSAGE (loss trÃªn Câ€“C graph)...\n",
      "[hetero] Epoch 01 | loss = 1.5946\n",
      "[hetero] Epoch 02 | loss = 1.4815\n",
      "[hetero] Epoch 03 | loss = 1.3937\n",
      "[hetero] Epoch 04 | loss = 1.3638\n",
      "[hetero] Epoch 05 | loss = 1.3526\n",
      "[hetero] Epoch 06 | loss = 1.3251\n",
      "[hetero] Epoch 07 | loss = 1.3107\n",
      "[hetero] Epoch 08 | loss = 1.2959\n",
      "[hetero] Epoch 09 | loss = 1.2842\n",
      "[hetero] Epoch 10 | loss = 1.2645\n",
      "[hetero] Epoch 11 | loss = 1.2460\n",
      "[hetero] Epoch 12 | loss = 1.2326\n",
      "[hetero] Epoch 13 | loss = 1.2226\n",
      "[hetero] Epoch 14 | loss = 1.2163\n",
      "[hetero] Epoch 15 | loss = 1.2107\n",
      "[hetero] Epoch 16 | loss = 1.2068\n",
      "[hetero] Epoch 17 | loss = 1.2019\n",
      "[hetero] Epoch 18 | loss = 1.1989\n",
      "[hetero] Epoch 19 | loss = 1.1953\n",
      "[hetero] Epoch 20 | loss = 1.1936\n",
      "[hetero] Epoch 21 | loss = 1.1920\n",
      "[hetero] Epoch 22 | loss = 1.1899\n",
      "[hetero] Epoch 23 | loss = 1.1877\n",
      "[hetero] Epoch 24 | loss = 1.1871\n",
      "[hetero] Epoch 25 | loss = 1.1858\n",
      "[hetero] Epoch 26 | loss = 1.1840\n",
      "[hetero] Epoch 27 | loss = 1.1835\n",
      "[hetero] Epoch 28 | loss = 1.1816\n",
      "[hetero] Epoch 29 | loss = 1.1801\n",
      "[hetero] Epoch 30 | loss = 1.1792\n",
      "[hetero] Epoch 31 | loss = 1.1785\n",
      "[hetero] Epoch 32 | loss = 1.1774\n",
      "[hetero] Epoch 33 | loss = 1.1763\n",
      "[hetero] Epoch 34 | loss = 1.1745\n",
      "[hetero] Epoch 35 | loss = 1.1743\n",
      "[hetero] Epoch 36 | loss = 1.1732\n",
      "[hetero] Epoch 37 | loss = 1.1727\n",
      "[hetero] Epoch 38 | loss = 1.1715\n",
      "[hetero] Epoch 39 | loss = 1.1705\n",
      "[hetero] Epoch 40 | loss = 1.1701\n",
      "[hetero] Epoch 41 | loss = 1.1694\n",
      "[hetero] Epoch 42 | loss = 1.1690\n",
      "[hetero] Epoch 43 | loss = 1.1687\n",
      "[hetero] Epoch 44 | loss = 1.1684\n",
      "[hetero] Epoch 45 | loss = 1.1677\n",
      "[hetero] Epoch 46 | loss = 1.1678\n",
      "[hetero] Epoch 47 | loss = 1.1674\n",
      "[hetero] Epoch 48 | loss = 1.1669\n",
      "[hetero] Epoch 49 | loss = 1.1677\n",
      "[hetero] Epoch 50 | loss = 1.1668\n",
      "[hetero] Epoch 51 | loss = 1.1674\n",
      "[hetero] Epoch 52 | loss = 1.1659\n",
      "[hetero] Epoch 53 | loss = 1.1669\n",
      "[hetero] Epoch 54 | loss = 1.1658\n",
      "[hetero] Epoch 55 | loss = 1.1662\n",
      "[hetero] Epoch 56 | loss = 1.1652\n",
      "[hetero] Epoch 57 | loss = 1.1662\n",
      "[hetero] Epoch 58 | loss = 1.1653\n",
      "[hetero] Epoch 59 | loss = 1.1656\n",
      "[hetero] Epoch 60 | loss = 1.1645\n",
      "[hetero] Epoch 61 | loss = 1.1646\n",
      "[hetero] Epoch 62 | loss = 1.1647\n",
      "[hetero] Epoch 63 | loss = 1.1652\n",
      "[hetero] Epoch 64 | loss = 1.1643\n",
      "[hetero] Epoch 65 | loss = 1.1639\n",
      "[hetero] Epoch 66 | loss = 1.1639\n",
      "[hetero] Epoch 67 | loss = 1.1640\n",
      "[hetero] Epoch 68 | loss = 1.1637\n",
      "[hetero] Epoch 69 | loss = 1.1637\n",
      "[hetero] Epoch 70 | loss = 1.1633\n",
      "[hetero] Epoch 71 | loss = 1.1625\n",
      "[hetero] Epoch 72 | loss = 1.1626\n",
      "[hetero] Epoch 73 | loss = 1.1630\n",
      "[hetero] Epoch 74 | loss = 1.1619\n",
      "[hetero] Epoch 75 | loss = 1.1628\n",
      "[hetero] Epoch 76 | loss = 1.1624\n",
      "[hetero] Epoch 77 | loss = 1.1625\n",
      "[hetero] Epoch 78 | loss = 1.1626\n",
      "[hetero] Epoch 79 | loss = 1.1626\n",
      "[hetero] Epoch 80 | loss = 1.1620\n",
      "â±ï¸ Done training in 23.47s\n"
     ]
    }
   ],
   "source": [
    "def train_one_epoch_hetero(epoch: int, num_negative: int = 10, max_edges: int = 400_000):\n",
    "    \"\"\"\n",
    "    - Forward trÃªn Hetero graph (toÃ n bá»™ edge types).\n",
    "    - Láº¥y embedding Computer.\n",
    "    - DÃ¹ng contrastive loss trÃªn Câ€“C graph (giá»‘ng code cÅ©).\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 1) Hetero GraphSAGE: node embedding cho táº¥t cáº£ node types\n",
    "    x_dict = model(edge_index_dict_device)   # dict[node_type] -> [N_nt, d]\n",
    "    z_comp = x_dict[\"Computer\"]              # [num_nodes_computer, d]\n",
    "\n",
    "    # 2) Contrastive loss trÃªn Câ€“C graph\n",
    "    src_all, dst_all = edge_index_cc\n",
    "    num_edges = src_all.size(0)\n",
    "\n",
    "    if max_edges is not None and num_edges > max_edges:\n",
    "        perm = torch.randperm(num_edges, device=device)[:max_edges]\n",
    "        src = src_all[perm]\n",
    "        dst = dst_all[perm]\n",
    "    else:\n",
    "        src = src_all\n",
    "        dst = dst_all\n",
    "\n",
    "    # Positive pairs\n",
    "    pos_src = z_comp[src]\n",
    "    pos_dst = z_comp[dst]\n",
    "    pos_scores = (pos_src * pos_dst).sum(dim=-1)\n",
    "    pos_loss = -F.logsigmoid(pos_scores).mean()\n",
    "\n",
    "    # Negative sampling\n",
    "    neg_dst_idx = torch.randint(\n",
    "        0,\n",
    "        z_comp.size(0),\n",
    "        (src.size(0) * num_negative,),\n",
    "        device=device,\n",
    "    )\n",
    "    neg_src = pos_src.repeat_interleave(num_negative, dim=0)\n",
    "    neg_dst = z_comp[neg_dst_idx]\n",
    "\n",
    "\n",
    "\n",
    "    neg_scores = (neg_src * neg_dst).sum(dim=-1)\n",
    "    neg_loss = -F.logsigmoid(-neg_scores).mean()\n",
    "\n",
    "    loss = pos_loss + neg_loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"[hetero] Epoch {epoch:02d} | loss = {loss.item():.4f}\")\n",
    "    return loss.item()\n",
    "\n",
    "print(\"\\nğŸ”¥ Start training HeteroGraphSAGE (loss trÃªn Câ€“C graph)...\")\n",
    "start_time = time.time()\n",
    "num_epochs = 80\n",
    "\n",
    "for ep in range(1, num_epochs + 1):\n",
    "    train_one_epoch_hetero(ep)\n",
    "\n",
    "print(f\"â±ï¸ Done training in {time.time() - start_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210fd3bd",
   "metadata": {
    "papermill": {
     "duration": 0.040025,
     "end_time": "2025-11-30T08:14:00.741130",
     "exception": false,
     "start_time": "2025-11-30T08:14:00.701105",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7. Láº¥y node embedding & sinh path embedding tá»« (C0, C2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9728401c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T08:14:00.822796Z",
     "iopub.status.busy": "2025-11-30T08:14:00.822563Z",
     "iopub.status.idle": "2025-11-30T08:14:11.216745Z",
     "shell.execute_reply": "2025-11-30T08:14:11.215862Z"
    },
    "papermill": {
     "duration": 10.436844,
     "end_time": "2025-11-30T08:14:11.217876",
     "exception": false,
     "start_time": "2025-11-30T08:14:00.781032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¯ Generating path embeddings from Computer embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All paths for cls: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.76it/s]\n",
      "Normal paths: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 119/119 [00:10<00:00, 11.87it/s]\n",
      "Malicious train/val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 216.48it/s]\n",
      "Malicious test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 265.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Example embedding shape: torch.Size([128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x_dict = model(edge_index_dict_device)\n",
    "    z_comp = x_dict[\"Computer\"]  # [num_nodes_computer, d]\n",
    "\n",
    "def batch_path_embeddings_from_CUC(paths, x_dict, desc: str, batch_size: int = 4096):\n",
    "    \"\"\"\n",
    "    paths: list cÃ¡c path (C, U, C) vá»›i index local theo tá»«ng node type.\n",
    "    x_dict: dict node_type -> embedding tensor tá»« model (Computer, User, ...)\n",
    "    Tráº£ vá» dict: path_tuple -> emb (mean(C0, U, C2), L2-normalized)\n",
    "    \"\"\"\n",
    "    device = next(iter(x_dict.values())).device\n",
    "    z_comp = x_dict[\"Computer\"]\n",
    "    z_user = x_dict[\"User\"]\n",
    "\n",
    "    res = {}\n",
    "    n = len(paths)\n",
    "\n",
    "    for i in tqdm(range(0, n, batch_size), desc=desc):\n",
    "        batch = paths[i:i + batch_size]\n",
    "        if not batch:\n",
    "            continue\n",
    "\n",
    "        # [B, 3] index cho (C0, U, C2)\n",
    "        idx = torch.tensor(batch, dtype=torch.long, device=device)  # shape [B, 3]\n",
    "        c0_idx = idx[:, 0]\n",
    "        u_idx  = idx[:, 1]\n",
    "        c2_idx = idx[:, 2]\n",
    "\n",
    "        emb_c0 = z_comp[c0_idx]   # [B, d]\n",
    "        emb_u  = z_user[u_idx]    # [B, d]\n",
    "        emb_c2 = z_comp[c2_idx]   # [B, d]\n",
    "\n",
    "        emb = (emb_c0 + emb_u + emb_c2) / 3.0\n",
    "        emb = F.normalize(emb, p=2, dim=-1)\n",
    "\n",
    "        for p, e in zip(batch, emb):\n",
    "            res[tuple(p)] = e.detach().cpu()\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "print(\"\\nğŸ¯ Generating path embeddings from Computer embeddings...\")\n",
    "\n",
    "path_embedding = batch_path_embeddings_from_CUC(\n",
    "    all_paths_for_cls,\n",
    "    x_dict,\n",
    "    desc=\"All paths for cls\",\n",
    "    batch_size=4096,\n",
    ")\n",
    "\n",
    "\n",
    "out_normal = batch_path_embeddings_from_CUC(\n",
    "    normal_path,\n",
    "    x_dict,\n",
    "    desc=\"Normal paths\",\n",
    "    batch_size=4096,\n",
    ")\n",
    "\n",
    "out_mal_train_val = batch_path_embeddings_from_CUC(\n",
    "    malicious_train_val_path,\n",
    "    x_dict,\n",
    "    desc=\"Malicious train/val\",\n",
    "    batch_size=4096,\n",
    ")\n",
    "\n",
    "out_mal_test = batch_path_embeddings_from_CUC(\n",
    "    malicious_test_path,\n",
    "    x_dict,\n",
    "    desc=\"Malicious test\",\n",
    "    batch_size=4096,\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Example embedding shape:\", next(iter(path_embedding.values())).shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034a6071",
   "metadata": {
    "papermill": {
     "duration": 0.045637,
     "end_time": "2025-11-30T08:14:11.310479",
     "exception": false,
     "start_time": "2025-11-30T08:14:11.264842",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8. LÆ°u káº¿t quáº£ giá»‘ng format MetaPath2Vec/GraphSAGE cÅ© \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bda11c29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T08:14:11.402669Z",
     "iopub.status.busy": "2025-11-30T08:14:11.402414Z",
     "iopub.status.idle": "2025-11-30T08:14:30.389551Z",
     "shell.execute_reply": "2025-11-30T08:14:30.388781Z"
    },
    "papermill": {
     "duration": 19.034379,
     "end_time": "2025-11-30T08:14:30.390718",
     "exception": false,
     "start_time": "2025-11-30T08:14:11.356339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¾ Saved all outputs to: /kaggle/working/model_graphsage_CUC_hetero_20251130081411\n"
     ]
    }
   ],
   "source": [
    "\n",
    "datestring = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "cur_dir = os.getcwd()\n",
    "store_directory = os.path.join(cur_dir, f\"model_graphsage_CUC_hetero_{datestring}\")\n",
    "os.mkdir(store_directory)\n",
    "\n",
    "# lÆ°u state_dict thay vÃ¬ full model object\n",
    "torch.save(model.state_dict(), os.path.join(store_directory, \"model_state.pt\"))\n",
    "torch.save(all_paths_for_cls, os.path.join(store_directory, \"path.pt\"))\n",
    "torch.save(path_embedding, os.path.join(store_directory, \"path_embedding.pt\"))\n",
    "torch.save(labels, os.path.join(store_directory, \"path_labels.pt\"))\n",
    "\n",
    "torch.save(out_normal, os.path.join(store_directory, \"out_normal.pt\"))\n",
    "torch.save(out_mal_train_val, os.path.join(store_directory, \"out_mal_train_val.pt\"))\n",
    "torch.save(out_mal_test, os.path.join(store_directory, \"out_mal_test.pt\"))\n",
    "\n",
    "print(f\"\\nğŸ’¾ Saved all outputs to: {store_directory}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 280004749,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 280328133,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 282.238717,
   "end_time": "2025-11-30T08:14:32.658257",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-30T08:09:50.419540",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
